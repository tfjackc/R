---
title: "Spatial Data Visualization for Tornado Alley"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---
### Jack Colpitt
#### **Goals** -- Take you on a tutorial of the capabilities of spatial data visualization within the R ecosystem. 

##### We will use the libraries listed below to import a set of shapefiles, and plot data to display tornado density based on the counties that intersect our point and polyline data, and what year the events took place. 

```{r,warning=FALSE,message=FALSE}
library(sf)           
library(rgdal)        
library(ggplot2)      
library(dplyr)        
library(tidyr)        
library(scales)       
library(RColorBrewer) 
library(units)
library(cowplot)
library(here)
```

#### **Import Data**
The "ok_counties.shp" dataset contains county boundaries for the state of Oklahoma. The "ok_tornado_point.shp" dataset and the "ok_tornado_path.shp" dataset contain historical information about tornadoes in Oklahoma. The points are the initial locations of tornado touchdown, and the paths are lines that identify the path of each tornado after touchdown. These data were derived from larger, national-level datasets generated by the National Oceanographic and Atmospheric Administration (NOAA) National Weather Service Storm Prediction Center https://www.spc.noaa.gov/gis/svrgis/ (Wimberly, n.d.).

```{r}
# convert each shapefile into a simple feature using the st_read function from the sf library. 
okcounty <- st_read(here("data", "ok_counties.shp"), quiet = TRUE)
tpoint <- st_read(here("data", "ok_tornado_point.shp"), quiet = TRUE)
tpath <- st_read(here("data", "ok_tornado_path.shp"), quiet = TRUE)
```
#### **Preview Data**
Lets take a look at the okcounty simple features dataframe using the glimpse function to see what variables are available.
```{r}
# use glimpse function and print the results below.
glimpse(okcounty)
```
The okcounty dataset provides the geometry and county names for us to derive some simple information. Eventually we will need to leverage the sf library to intersect the points, polylines, with the county polygons to derive more insights from the available data.

#### **Filter tornado points and polylines based on the year**
Lets start by filtering the data, and then previewing the paths with unique symbology based on the year of the event.

```{r}
# filter the tornado touchdown and path data from years between 2016 and 2021.
tpoint_16_21 <- tpoint %>% 
  filter(yr >= 2016 & yr <= 2021) %>%
  select(om, yr, date)

tpath_16_21 <- tpath %>%
  filter(yr >= 2016 & yr <= 2021) %>%
  select(om, yr, date)
```
#### **Plot the data, create .tiff files, and use the plot_grid() function to display the images**
The code below will generate two plots: one displaying the routes of tornadoes that happened in Oklahoma from 2016 to 2021, and another displaying the locations where tornadoes touched down in Oklahoma during that same time period. The plots will be saved as tiff files and then merged into a single plot grid. The plot grid will have two columns, and the plots will be vertically oriented.
```{r}
tpath_years <- ggplot() + # use ggplot to create the plot.
                  geom_sf(data = tpath_16_21, # use geom_sf to plot the polyline geometry.
                          aes(color = as.factor(yr)),
                          linewidth = 1) + # color based on year.
                  geom_sf(data = okcounty, fill = NA) + # plot polygon geometry
                  scale_color_discrete(name = "Year") + # set color scale
                  coord_sf(datum = NA) + # put geometries on the same coordinate reference system
                  theme_void() # remove plot lines

tpoint_years <- ggplot() + # use ggplot to create the plot.
                  geom_sf(data = tpoint_16_21, # use geom_sf to plot the point geometry.
                          aes(color = as.factor(yr))) + # color based on year.
                  geom_sf(data = okcounty, fill = NA) + # plot polygon geometry
                  scale_color_discrete(name = "Year") + # set color scale
                  coord_sf(datum = NA) + # put geometries on the same coordinate reference system
                  theme_void() # remove plot lines

ggsave("tpath_years.tiff", # save as .tiff file
       width = 6, 
       height = 6, 
       dpi = 300, 
       compression = "lzw")

ggsave("tpoint_years.tiff", # save as .tiff file
       width = 6, 
       height = 6, 
       dpi = 300, 
       compression = "lzw")

plot_grid(tpath_years, tpoint_years, # create a plot grid of the tornado path and point plots.
          labels = c("A) Tornado Paths", 
                     "B) Tornado Points",
                     label_size = 12),
          ncol = 1, # 1 column
          rel_heights = c(1, 1), # set the relative heights of the plots in the plot grid to be equal.
          align = "hv",
          vjust = 5) # adjust where the titles sit on the plot grid.
```
#### **Spatial Join & summarize within**
The next step will be to the visualize the density of tornadoes within each county based on the year. 

* We will need to use a spatial join with the sf libary to merge our filtered tornado points with the Oklahoma counties.
* Then count the number of tornadoes using group_by & summarize

```{r}
# use the spatial join operation create a new dataframe based on the tornadoes within each county
countypnt <- st_join(tpoint_16_21, okcounty)

# convert to a non spatial dataframe
countypnt <- st_drop_geometry(countypnt)
countysum <- countypnt %>%
  group_by(GEOID) %>% # group by counties 
  summarize(tcnt = n()) # count the tornadoes within each county
```
#### **Join dataframes and create density based on the summarized findings**
The results below will give us a glimpse of the newly available statistics on which we can create more insightful visualizations. The code below is performing the following operations...

* Left join on the countysum dataframe -- This guarantees that the join result contains all of the county polygons.
* Calculate area of each county and use tcnt variables divided by the area to create a density variable.

```{r}
countymap <- okcounty %>%
  left_join(countysum, by = "GEOID") %>% # join the countysum data with the okcounty data on GEOID
  replace(is.na(.), 0) %>% # replace non available observations with 0
  mutate(area = st_area(okcounty),
         tdens = 10^6 * 10^3 * tcnt / area) %>% # calculate the area of each county and the tornado density
  drop_units() # drop the units from the area and tdens variables
glimpse(countymap) # preview the results
```
#### **Join countymap with countypnt and display using a faceted plot**
Our goal in the next visualization is to summarize the density of tornado points by both county and year and generate a faceted plot that displays maps of county-level tornado density from 2016-2021.

* The two variables needed to display the desired results are density and year, which are contained in two different dataframes -- countymap and countypnt.
* Use another left join, and filter out years that equal zero.
* Plot new dataframe with the facet_wrap function to display the state of Oklahoma for each year.

```{r}
# join countymap and countypnt with a left_join
df_join <- countymap %>%
  left_join(countypnt, by = "GEOID") %>% # join based on the GEOID variable
  replace(is.na(.), 0) %>% # replace non available observations with 0
  filter(yr != 0) # filter out where years equal zero

ggplot(data = df_join) + # plot df_join.
  geom_sf(aes(fill = tdens)) + # color based on density
  geom_sf(data = okcounty, 
          fill = NA,
          color = "gray") +
  scale_fill_distiller(name = expression("Tornadoes/1000 km"^2),
                       palette = "YlOrRd",
                       breaks = pretty_breaks(),
                       direction = 1) +
  facet_wrap(vars(yr), ncol = 2) + # divide the plots up by the year
  coord_sf(datum = NA) + # put geometries on the same coordinate reference system
  theme_void() +
  theme(legend.position = "bottom")
```
The visualization above represents the scale of tornado activity across the state from 2016 to 2021. As you can see Tulsa county experiences the most activity in comparison to the other counties. 

#### **Create a column of plots using plot_grid()**
Now that we have seen density represented by the year, lets organize our data into a variety of class breaks ranging from 3 to 6 to understand how this manipulates the analysis. The code below is programmatically going to loop through the range and set the class breaks for each plot. Using a for loop will help to reduce redundancy in the lines of code. 

* One of the most important notes for the R chunk is to assign the fig.width and fig.height in the "chunk options" -> ```{r, fig.width=10,fig.height=11} or else the plots will be too small to analyze properly.

```{r, fig.width=10,fig.height=11}
# Create an empty list to store the ggplot objects
ggplot_list <- list()

# create a range and loop through assigning the values to the qbrks variable, ggplot_list, and the .png files
for (i in 3:6) { 
  numclas <- i
  qbrks <- seq(0, 1, length.out = numclas + 1) # increase the qbrks variable by 1 in each loop
  
  # assign the observations to the new tdens_c1 column
  countymap <- countymap %>%
    mutate(tdens_c1 = cut(tdens,
                          breaks = quantile(tdens, probs = qbrks),
                          include.lowest = TRUE))
  
  # create the ggplot object and assign it to a variable
  plot <- ggplot(data = countymap) +
    geom_sf(aes(fill = tdens_c1)) +
    scale_fill_brewer(name = expression("Tornadoes/1000 km"^2),
                      palette = "YlOrRd") +
    theme_void() +
    theme(legend.position = "bottom")
  
  # save the ggplot object to the list
  ggplot_list[[i]] <- plot
  
  ggsave(paste0("tornado", i, "breaks.png"),
         width = 6,
         height = 4,
         dpi = 300)
}

# use plot_grid() to visualize the list of plots
plot_grid(ggplot_list[[3]], 
          ggplot_list[[4]], 
          ggplot_list[[5]],                    
          ggplot_list[[6]],
          align = "hv", ncol = 1) # use 1 column
```
By adding more detail, lowering distortion, and enhancing flexibility, increasing the number of quantile class splits can enhance visualization. However, it can also increase the complexity, length, and difficulty of visualizations. You can observe the variations above, and see a clear trend that tornado alley predominately runs from the Southwest corner to the Northeast corner of the state. In my opinion the clearest plot to read involves four class breaks.

#### **Resources**:

Wimberly, M. C. (n.d.). Chapter 5 Vector Geospatial Data | Geographic Data Science with R: Visualizing and Analyzing Environmental Change. Chapter 5 Vector Geospatial Data | Geographic Data Science With R: Visualizing and Analyzing Environmental Change. https://bookdown.org/mcwimberly/gdswr-book/vector-geospatial-data.html

